# -*- coding: utf-8 -*-
"""GithubInsightsTraffic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ut1kOhk-oRhcfIqyhx5AP3avafeNhmcV
"""

import requests, time, json, statistics, datetime, os
from influxdb import InfluxDBClient
from dotenv import load_dotenv

load_dotenv()

HEADERS = {
    'Accept': 'application/vnd.github.v3+json',
    'Authorization': os.getenv('AUTH_TOKEN')
}

# get repositories
repos_url = "https://api.github.com/users/"+str(os.getenv("AUTHOR"))+"/repos?page="
repositories = []
for i in range(1, 100):
  buffer_url = repos_url+str(i)
  print(f"buffer url: {buffer_url}")
  content = json.loads(requests.get(buffer_url).content)
  if content==[]:
    print(f"[debug] - empty result, break out of the loop")
    break
  for repo in content:
    repositories.append(repo)
nb_repos = len(repositories)
print(nb_repos)

# get repo's data
views_url = "https://api.github.com/repos/"+str(os.getenv('AUTHOR'))+"/XXX/traffic/views"
clones_url = "https://api.github.com/repos/"+str(os.getenv('AUTHOR'))+"/XXX/traffic/clones"

def check_request(url, header=None):
  req = requests.get(url, headers=HEADERS)
  if req.status_code==200:
    return json.loads(req.content)
  else:
    return None


def fetch_data(repos):
  viewers, unique_viewers, cloners, unique_cloners = [], [], [], []
  for repo in repos:
    # fill parameterized urls
    buffer_view = views_url.replace('XXX', repo['name'])
    buffer_clone = clones_url.replace('XXX', repo['name'])
    
    # send requests
    views = check_request(buffer_view)
    if views is not None:
      viewers.append(views['count'])
      unique_viewers.append(views['uniques'])

    clones = check_request(buffer_clone)
    if clones is not None:
      cloners.append(views['count'])
      unique_cloners.append(views['uniques'])

  return {
      'views': viewers, 'unique_viewers': unique_viewers, 'clones': cloners, 'unique_cloners': unique_cloners
  }

res = fetch_data(repositories)
print(res)

# make result in shape
def avg(li):
  return round(sum(li)/len(li), 2)

def median(li):
  return int(statistics.median(li))

def get_percentage(li):
    ct=0
    for l in li:
        if l==0:
            ct+=1
    return round(100-(100*ct/len(li)), 2)

result = {
    'views': sum(res['views']),
    'unique_viewers': sum(res['unique_viewers']),
    'clones': sum(res['clones']),
    'unique_cloners': sum(res['unique_cloners']),
    'max_views': max(res['views']),
    'max_clones': max(res['clones']),
    'max_unique_viewers': max(res['unique_viewers']),
    'max_unique_cloners': max(res['unique_cloners']),
    'nb_repositories': nb_repos,
    'percentage_cloned': get_percentage(res['clones']),
    'percentage_viewed': get_percentage(res['views']),
    'mean_views': avg(res['views']),
    'mean_clones': avg(res['clones']),
    'mean_unique_viewers': avg(res['unique_viewers']),
    'mean_unique_cloners': avg(res['unique_cloners']),
    'median_views': median(res['views']),
    'median_clones': median(res['clones']),
    'median_unique_viewers': median(res['unique_viewers']),
    'median_unique_cloners': median(res['unique_cloners'])
}

print(result)

client = InfluxDBClient(os.getenv('HOST'), os.getenv('PORT'), os.getenv('USER'), os.getenv('PWD'), os.getenv('DBNAME'))
json_body = [{
    "measurement": os.getenv('MEASUREMENT'),
    "time": datetime.datetime.utcnow(),
    "fields": result
}]

client.write_points(json_body)